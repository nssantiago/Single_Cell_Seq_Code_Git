{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113d7db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata, math, pickle, os, fnmatch\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import matplotlib as mlp\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "from matplotlib import colors\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.ticker import MultipleLocator, LogLocator, LogFormatter, LogFormatterSciNotation, MaxNLocator\n",
    "import matplotlib.patches as mpatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3707776e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''IMPORTING FUNCTIONS FROM GENERAL FUNCTIONS FILE'''\n",
    "\n",
    "%run GeneralFunctions.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34c248c",
   "metadata": {},
   "source": [
    "# Calculation Functions Figure 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d618f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finds the number of nuclei in a cluster for a sample \n",
    "    # sampleObj = AnnData object of the \n",
    "def findClustNum(sampleObj):\n",
    "    # List where all of the nucleus counts will be held\n",
    "    nucPerClust = []\n",
    "    \n",
    "    # Cluster number for sample list  \n",
    "    clustLst = np.unique(list(sampleObj.obs['leiden_0.3']))\n",
    "    \n",
    "    print(clustLst)\n",
    "    # Going through each cluster and finding the number of nuclei \n",
    "    for clust in clustLst:\n",
    "        clustObj = sampleObj[sampleObj.obs['leiden_0.3'].isin([clust]),:]\n",
    "        nucNum = clustObj.n_obs\n",
    "        nucPerClust.append(nucNum)\n",
    "    \n",
    "    return(nucPerClust)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee62b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finds the percentile to use for max on the color bar in UMAPS\n",
    "def percentileCalc(obj, gene):\n",
    "    objGeneLst = list(obj.var_names)\n",
    "    geneIdx = objGeneLst.index(gene)\n",
    "    geneExpLst = obj.X.toarray()\n",
    "    geneExp = [row[geneIdx] for row in geneExpLst]\n",
    "    \n",
    "    if (np.percentile(geneExp, 95)) > 0:\n",
    "        return 'p95'\n",
    "    elif (np.percentile(geneExp, 99)) > 0:\n",
    "        return 'p99'\n",
    "    else:\n",
    "        return(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf2280f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Averages the gene expression matrix across all cells (Helper Function for 'calculatingCorrelationMatrix')\n",
    "    # dataObject = AnnData object you want to calculate the vector mean for \n",
    "    # clusterStr = List containing all of the clusters in the data object \n",
    "def calculatingVectorMeans(dataObject, clusterStr):\n",
    "   \n",
    "    # Creating AnnData Object for the chosen cluster from the chosen data\n",
    "    clusterObj = dataObject[dataObject.obs['leiden_0.3'].isin([clusterStr]),:]\n",
    "    # Turning the mean gene expression data for the cluster specified into a 2D list that can be averaged along rows \n",
    "    geneExpression = clusterObj.X.toarray()\n",
    "    \n",
    "    # Holds the mean of each col for all rows \n",
    "    vectorMean = []\n",
    "    # Number of nuclei in the cluster specified (in dataObject.obs)\n",
    "    nucleiCount = dataObject.n_obs\n",
    "    # Number of genes looked at in the data (in dataObject.vars)\n",
    "    geneCount = (len(geneExpression[0]))\n",
    "    \n",
    "    # Iterating through each column of the gene count array\n",
    "    for i in range (geneCount):\n",
    "        # Contains the sum for the same column in each row \n",
    "        geneSumPerCol = 0 \n",
    "        # Iterating through each row of the gene count array \n",
    "        for vector in geneExpression:\n",
    "            # Adding the same column per row \n",
    "            geneSumPerCol += vector[i]\n",
    "        # Averaging the gene sums for the same column in all rows   \n",
    "        aveGeneExp = geneSumPerCol / nucleiCount \n",
    "        # Adding the average for that column into the vectorMean list \n",
    "        vectorMean.append(aveGeneExp)\n",
    "    \n",
    "    return vectorMean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5684bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates the correlation matrix formatted for plotting a correlation heatmap (Helper Function for 'betweenSampleCorrelationCalculations')\n",
    "    # clustLst_Half1 = List of the clusters found in the first half of the data \n",
    "    # data_Half1 = AnnData object of the first half of the data \n",
    "    # clustLst_Half2 = List of the clusters found in the second half of the data \n",
    "    # data_Half2 = AnnData object of the second half of the data \n",
    "def calculatingCorrelationMatrix(clustLst_Half1, data_Half1, clustLst_Half2, data_Half2):\n",
    "    # sorting the list of cluster numbers for each sample \n",
    "    sortedClusters_Half1 = sortClust(clustLst_Half1)\n",
    "    sortedClusters_Half2 = sortClust(clustLst_Half2)\n",
    "    \n",
    "    # Dictionary to hold vector means for each cluster \n",
    "    clusterMeans_Half1 = {}\n",
    "    clusterMeans_Half2 = {}\n",
    "    \n",
    "    # Calculating the vector means for each cluster in Half 1\n",
    "    for cluster_Half1 in sortedClusters_Half1:\n",
    "        vectorMean_Half1 = calculatingVectorMeans(data_Half1, cluster_Half1)\n",
    "        clusterMeans_Half1[cluster_Half1] = vectorMean_Half1\n",
    "        \n",
    "    # Calculating the vector means for each cluster in Half 2\n",
    "    for cluster_Half2 in sortedClusters_Half2:\n",
    "        vectorMean_Half2 = calculatingVectorMeans(data_Half2, cluster_Half2)\n",
    "        clusterMeans_Half2[cluster_Half2] = vectorMean_Half2\n",
    "    \n",
    "    # where the matrix of the correlations is going to be held \n",
    "    corrMtrx = []\n",
    "    \n",
    "    # Looping through all of the clusters in sample half 1 \n",
    "    for cluster_Half1 in clusterMeans_Half1: \n",
    "        row = []\n",
    "        vectorMean_Half1 = clusterMeans_Half1[cluster_Half1]\n",
    "        \n",
    "        # Looping through all of the clusters in sample half 2 \n",
    "        for cluster_Half2 in clusterMeans_Half2:\n",
    "            vectorMean_Half2 = clusterMeans_Half2[cluster_Half2]\n",
    "            # calculating the correlation of the two vectors \n",
    "            corrValue = np.corrcoef(vectorMean_Half1, vectorMean_Half2)[0, 1]\n",
    "            # putting the correlation value into the list \n",
    "            row.append(corrValue)\n",
    "        # putting the row of correlation values into the list \n",
    "        corrMtrx.append(row)\n",
    "\n",
    "    return corrMtrx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9836aca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates the correlation heatmap matrix for a provided list of sample comaprisons you want to make and saves all \n",
    "# comparisons in a dictionary \n",
    "    # sampleComparisonLst = List containing strings of the comparisons you want to make \n",
    "        # Ex. [['sample1 and 2 condition', 'sample1', 'sample2'], ['sample3 and 4 condition', 'sample3', 'sample4'], etc...] \n",
    "def betweenSampleCorrelationCalculations(sampleComparisonLst):\n",
    "    # Dictionary where the correlations for each sample will be held \n",
    "    corrMtx_dict = {}\n",
    "    \n",
    "    # Folder path for each sample half file \n",
    "    folderPath = f'F:/SampleData/SampleHalves/'\n",
    "    \n",
    "    # Looping through each sample comparison in the list \n",
    "    for sampleLst in sampleComparisonLst: \n",
    "        \n",
    "        # Getting condition and name information for each sample \n",
    "        condition = sampleLst[0]\n",
    "        sample1_name = sampleLst[1]\n",
    "\n",
    "        # Getting folder paths for each half of sample 1\n",
    "        sample1_half1_pathLst =  search_files(folderPath, f'{sample1_name}_Half1')\n",
    "        sample1_half2_pathLst =  search_files(folderPath, f'{sample1_name}_Half2')\n",
    "\n",
    "        # Reading AnnData object for each sample half \n",
    "        sample1_half1 = sc.read(sample1_half1_pathLst[0])\n",
    "        sample1_half2 = sc.read(sample1_half2_pathLst[0])\n",
    "\n",
    "        # List of cluster numbers for each sample half \n",
    "        sample1_half1_clustLst = list(np.unique(sample1_half1.obs['leiden_0.3']))\n",
    "        sample1_half2_clustLst = list(np.unique(sample1_half2.obs['leiden_0.3']))\n",
    "\n",
    "        # Getting information from sample 2 if we are doing between sample comparisons \n",
    "        if len(sampleLst) == 3: \n",
    "            # Getting sample name \n",
    "            sample2_name = sampleLst[2]\n",
    "            \n",
    "            # Getting folder paths for each half of sample 2\n",
    "            sample2_half1_pathLst =  search_files(folderPath, f'{sample2_name}_Half1')\n",
    "            sample2_half2_pathLst =  search_files(folderPath, f'{sample2_name}_Half2')\n",
    "            \n",
    "            # Reading AnnData object for each sample half \n",
    "            sample2_half1 = sc.read(sample2_half1_pathLst[0])\n",
    "            sample2_half2 = sc.read(sample2_half2_pathLst[0])\n",
    "            \n",
    "            # List of cluster numbers for each sample half \n",
    "            sample2_half1_clustLst = list(np.unique(sample2_half1.obs['leiden_0.3']))\n",
    "            sample2_half2_clustLst = list(np.unique(sample2_half2.obs['leiden_0.3']))\n",
    "            \n",
    "            # Calculating the correlation matrix for each sample \n",
    "            half1_corrMtx = calculatingCorrelationMatrix(sample1_half1_clustLst, sample1_half1, sample2_half1_clustLst, \n",
    "                                                         sample2_half1)\n",
    "            half2_corrMtx = calculatingCorrelationMatrix(sample1_half2_clustLst, sample1_half2, sample2_half2_clustLst, \n",
    "                                                     sample2_half2)\n",
    "            \n",
    "            # Adding each sample half to the dictionary \n",
    "            corrMtx_dict[f'{condition}_{sample1_name}_{sample2_name}_Half1'] = half1_corrMtx\n",
    "            corrMtx_dict[f'{condition}_{sample1_name}_{sample2_name}_Half2'] = half2_corrMtx\n",
    "            \n",
    "            print(sample1_name, sample2_name)\n",
    "        \n",
    "        else: \n",
    "            # Calculating correlation matrix for sample halves \n",
    "            corrMtx = calculatingCorrelationMatrix(sample1_half1_clustLst, sample1_half1, sample1_half2_clustLst, \n",
    "                                                   sample1_half2)\n",
    "            \n",
    "            # Adding correlation to dictionary \n",
    "            corrMtx_dict[sample1_name] = corrMtx\n",
    "        \n",
    "            print(sample1_name)\n",
    "            \n",
    "    return corrMtx_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d24c7b",
   "metadata": {},
   "source": [
    "# Plotting Functions Figure 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be8267a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOTTING FUNCTION: plots the best correlation between sample clusters\n",
    "def dotPlotBestCorrel(correlMatrix, sample1_name, fontSize, ax):\n",
    "\n",
    "    ylst = []\n",
    "    pointLabel = []\n",
    "\n",
    "    for correl in correlMatrix:\n",
    "        maxNum = max(correl)\n",
    "        numClst = correl.index(maxNum)\n",
    "        ylst.append(maxNum)\n",
    "        pointLabel.append(numClst)\n",
    "\n",
    "    # Sample data\n",
    "    x = [num for num in range (len(correlMatrix))]\n",
    "    y = ylst\n",
    "    \n",
    "    # Making dots numbers (# https://stackoverflow.com/questions/69251212/matlplotlib-scatterplot-with-numbers-as-symbols-legend)\n",
    "    ax.scatter(x, y, linestyle='None', color=\"white\") \n",
    "    \n",
    "    for i, txt in enumerate(pointLabel):\n",
    "        ax.annotate(txt, (x[i], y[i]), ha=\"center\", va=\"center\")\n",
    "\n",
    "    # Set the axis labels and title\n",
    "    ax.set_xlabel(f'Clusters in Sample {sample1_name}', fontsize = 15)\n",
    "    ax.set_ylabel('Correlation Value', fontsize = 15)\n",
    "    ax.set_title('Highest Correl. Values btw Samples', fontsize = fontSize)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_xticks(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e25920a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOTTING FUNCTION: plots best correlation vs. # of nuclei in cluster\n",
    "def dotPlotNucNum(correlMatrix, sample1, sample2, fontSize, legendKey, ax):\n",
    "    \n",
    "    y1lst = []\n",
    "    sample1_clustNum = np.unique(list(sample1.obs['leiden_0.3']))\n",
    "    sample1_pointLabel = sortClust(sample1_clustNum)\n",
    "\n",
    "    # Sample 1 data\n",
    "    for correl in correlMatrix:\n",
    "        maxNum = max(correl)\n",
    "        y1lst.append(maxNum)\n",
    "    \n",
    "    x1 = findClustNum(sample1)\n",
    "    y1 = y1lst\n",
    "\n",
    "    # Sample 2 data\n",
    "    \n",
    "    y2lst = []\n",
    "    sample2_clustNum = np.unique(list(sample2.obs['leiden_0.3']))\n",
    "    sample2_pointLabel = sortClust(sample2_clustNum)\n",
    "    \n",
    "    for i in range(len(correlMatrix[0])):\n",
    "        correlCol = [] \n",
    "        for correl in correlMatrix:\n",
    "            correlCol.append(correl[i])\n",
    "        maxNum = max(correlCol)\n",
    "        y2lst.append(maxNum)\n",
    "    \n",
    "    x2 = findClustNum(sample2)\n",
    "    y2 = y2lst\n",
    "    \n",
    "   # Scatter for Sample 1\n",
    "    ax.scatter(x1, y1, linestyle='None', color=\"white\", label='sample1') \n",
    "    \n",
    "    for i, txt in enumerate(sample1_pointLabel):\n",
    "        ax.annotate(txt, (x1[i], y1[i]), color='r', ha=\"center\", va=\"center\")\n",
    "    \n",
    "    # Scatter for Sample 2\n",
    "    ax.scatter(x2, y2, linestyle='None', color=\"white\") \n",
    "    \n",
    "    for i, txt in enumerate(sample2_pointLabel):\n",
    "        ax.annotate(txt, (x2[i], y2[i]), color='b', ha=\"center\", va=\"center\", label='sample2')\n",
    "\n",
    "    # Set the axis labels and title\n",
    "    ax.set_xlabel(f'Number of Nuclei', fontsize = 15)\n",
    "    ax.set_ylabel('Correlation Value', fontsize = 15)\n",
    "    ax.set_title('Highest Correl. vs Num. of Nuclei', fontsize = fontSize)\n",
    "    ax.set_ylim(0, 1)\n",
    "    \n",
    "    # Creating custom legend\n",
    "    if legendKey == 'halves':\n",
    "        patchA = mpatches.Patch(color='r', label='Sample Half 1')\n",
    "        patchB = mpatches.Patch(color='b', label='Sample Half 2')\n",
    "    else:\n",
    "        patchA = mpatches.Patch(color='r', label=legendKey[0])\n",
    "        patchB = mpatches.Patch(color='b', label=legendKey[1])\n",
    "    \n",
    "    ax.legend(handles=[patchA, patchB], loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746f5f06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
